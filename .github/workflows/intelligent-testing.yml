name: Intelligent Python Testing

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  intelligent-test-selection:
    runs-on: ubuntu-latest
    outputs:
      test-commands: ${{ steps.test-selector.outputs.commands }}
      run-full-tests: ${{ steps.test-selector.outputs.run-full-tests }}
      test-matrix: ${{ steps.test-selector.outputs.test-matrix }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Fetch full history for diff comparison
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
      
      - name: Run intelligent test selector
        id: test-selector
        shell: bash
        run: |
          # Make test selector executable
          chmod +x tools/test_selector.py
          
          # Determine the base reference to use
          BASE_REF="origin/main"
          if ! git rev-parse --verify $BASE_REF >/dev/null 2>&1; then
            echo "Warning: $BASE_REF not found, trying alternative references..."
            if git rev-parse --verify origin/main >/dev/null 2>&1; then
              BASE_REF="origin/main"
            elif git rev-parse --verify main >/dev/null 2>&1; then
              BASE_REF="main"
            else
              # Fallback to recent commits
              BASE_REF="HEAD~4"
            fi
          fi
          
          echo "Using base reference: $BASE_REF"
          
          # Run test selector and capture output
          python tools/test_selector.py --output-json --base $BASE_REF > test_selection.json
          
          # Parse the JSON output and set GitHub outputs
          cat test_selection.json
          
          # Extract commands for the next job
          commands=$(python -c "
          import json
          import sys
          try:
              with open('test_selection.json') as f:
                  data = json.load(f)
              print(json.dumps(data.get('commands', [])))
          except Exception as e:
              print('[]')  # Default to empty array if parsing fails
              sys.stderr.write(f'Warning: Error parsing test selection: {e}\n')
          ")
          
          # Check if we need full tests (fallback case)
          run_full=$(python -c "
          import json
          import sys
          try:
              with open('test_selection.json') as f:
                  data = json.load(f)
              full_tests = any('examples/testscript.py' in str(cmd) or (('pytest' in cmd) and len(cmd.split()) <= 3) for cmd in data.get('commands', []))
              print('true' if full_tests else 'false')
          except Exception as e:
              print('false')  # Default to not running full tests
              sys.stderr.write(f'Warning: Error checking full tests: {e}\n')
          ")
          
          echo "commands=$commands" >> $GITHUB_OUTPUT
          echo "run-full-tests=$run_full" >> $GITHUB_OUTPUT
          
          # Create test matrix for parallel execution
          matrix=$(python -c "
          import json
          import sys
          try:
              with open('test_selection.json') as f:
                  data = json.load(f)
              
              # Create matrix based on test categories
              categories = list(data.get('categories', {}).keys())
              commands = data.get('commands', [])
              
              if not commands:
                  matrix = [{'name': 'minimal', 'commands': ['echo \"No tests to run\"']}]
              elif 'docs' in categories and len(categories) == 1:
                  matrix = [{'name': 'docs-only', 'commands': [cmd for cmd in commands if 'docs' in cmd]}]
              elif 'superanimal' in categories:
                  matrix = [{'name': 'superanimal', 'commands': [cmd for cmd in commands if 'superanimal' in cmd or 'modelzoo' in cmd]}]
              else:
                  matrix = [{'name': 'selected-tests', 'commands': commands}]
              
              print(json.dumps(matrix))
          except Exception as e:
              # Fallback matrix if parsing fails
              matrix = [{'name': 'fallback', 'commands': ['echo \"Test selection failed, skipping tests\"']}]
              print(json.dumps(matrix))
              sys.stderr.write(f'Warning: Error creating test matrix: {e}\n')
          ")
          
          echo "test-matrix=$matrix" >> $GITHUB_OUTPUT

  fast-tests:
    needs: intelligent-test-selection
    if: needs.intelligent-test-selection.outputs.run-full-tests == 'false'
    runs-on: ${{ matrix.os }}
    
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        python-version: ["3.10"]
        test-config: ${{ fromJson(needs.intelligent-test-selection.outputs.test-matrix) }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: conda-incubator/setup-miniconda@v3
        with:
          channels: conda-forge,defaults
          channel-priority: strict
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies (minimal)
        shell: bash -el {0}
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install pytest
          # Only install minimal dependencies for fast tests
          pip install numpy pandas matplotlib scikit-learn

      - name: Install DeepLabCut (minimal)
        shell: bash -el {0}
        run: |
          pip install -e . --no-deps

      - name: Run selected tests
        shell: bash -el {0}
        run: |
          echo "Running test configuration: ${{ matrix.test-config.name }}"
          commands='${{ toJson(matrix.test-config.commands) }}'
          echo "Commands to run: $commands"
          
          # Parse and execute commands
          python -c "
          import json
          import subprocess
          import sys
          
          commands = json.loads('$commands')
          all_passed = True
          
          for i, cmd in enumerate(commands, 1):
              print(f'[{i}/{len(commands)}] Running: {cmd}')
              try:
                  result = subprocess.run(cmd.split(), check=True)
                  print(f'✅ Passed: {cmd}')
              except subprocess.CalledProcessError as e:
                  print(f'❌ Failed: {cmd}')
                  all_passed = False
          
          sys.exit(0 if all_passed else 1)
          "

  full-tests:
    needs: intelligent-test-selection
    if: needs.intelligent-test-selection.outputs.run-full-tests == 'true'
    uses: ./.github/workflows/python-package.yml